{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import (Row, functions as F)\n",
    "from sparknlp.base import DocumentAssembler, EmbeddingsFinisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, Word2VecApproach\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sparknlp\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = sparknlp.start(gpu=True, memory='28G')\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "PATH = r\"C:\\Users\\samue\\Documents\\Applied Data Science\\INFO-H518 Deep Learning\\Assignments\\A3\\Input\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72729</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Check out my op-ed on need for End Executive O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72730</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Yesterday, Betty &amp;amp; I had a great time lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72731</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>We are forever grateful for the service and sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72732</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Happy first day of school @CobbSchools! #CobbB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72733</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>#Zika fears realized in Florida. House GOP act...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72734 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Party         Handle  \\\n",
       "0        Democrat  RepDarrenSoto   \n",
       "1        Democrat  RepDarrenSoto   \n",
       "2        Democrat  RepDarrenSoto   \n",
       "3        Democrat  RepDarrenSoto   \n",
       "4        Democrat  RepDarrenSoto   \n",
       "...           ...            ...   \n",
       "72729  Republican    RepTomPrice   \n",
       "72730  Republican    RepTomPrice   \n",
       "72731  Republican    RepTomPrice   \n",
       "72732  Republican    RepTomPrice   \n",
       "72733  Republican    RepTomPrice   \n",
       "\n",
       "                                                   Tweet  \n",
       "0      Today, Senate Dems vote to #SaveTheInternet. P...  \n",
       "1      RT @WinterHavenSun: Winter Haven resident / Al...  \n",
       "2      RT @NBCLatino: .@RepDarrenSoto noted that Hurr...  \n",
       "3      RT @NALCABPolicy: Meeting with @RepDarrenSoto ...  \n",
       "4      RT @Vegalteno: Hurricane season starts on June...  \n",
       "...                                                  ...  \n",
       "72729  Check out my op-ed on need for End Executive O...  \n",
       "72730  Yesterday, Betty &amp; I had a great time lear...  \n",
       "72731  We are forever grateful for the service and sa...  \n",
       "72732  Happy first day of school @CobbSchools! #CobbB...  \n",
       "72733  #Zika fears realized in Florida. House GOP act...  \n",
       "\n",
       "[72734 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_PATH = os.path.join(os.getcwd(), 'Assignments', 'A3', 'Input')\n",
    "train = spark.createDataFrame(\n",
    "    pd.read_csv(PATH + r'\\Original\\train.csv', header=\"infer\", index_col=0).dropna()\n",
    ")\n",
    "test = spark.createDataFrame(\n",
    "    pd.read_csv(PATH + r'\\Original\\test.csv', header=\"infer\", index_col=0).dropna()\n",
    ")\n",
    "train.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('Tweet') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols(['token']) \\\n",
    "    .setOutputCol('normal_token') \\\n",
    "    .setCleanupPatterns([\"[^#A-Za-z]\", \"^https(.*)\", \"^#$\"])\n",
    "\n",
    "token_pipeline = Pipeline().setStages([\n",
    "    doc_assembler,\n",
    "    tokenizer,\n",
    "    normalizer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = token_pipeline \\\n",
    "    .fit(train) \\\n",
    "    .transform(train) \\\n",
    "    .selectExpr(['Party', 'Handle', 'Tweet', 'normal_token.result as Tokens']) \\\n",
    "    .withColumnRenamed('result', 'Tokens')\n",
    "\n",
    "train_vocab = train.select('Tokens') \\\n",
    "    .select(F.explode('Tokens').alias('Terms')) \\\n",
    "    .distinct() \\\n",
    "    .sort('Terms') \\\n",
    "    .toPandas()\n",
    "\n",
    "train_vocab_frequency = train.select('Tokens') \\\n",
    "    .select(F.explode('Tokens').alias('Terms')) \\\n",
    "    .groupBy('Terms').count() \\\n",
    "    .toDF('Terms', 'Count') \\\n",
    "    .sort('Count') \\\n",
    "    .toPandas()\n",
    "\n",
    "\n",
    "\n",
    "test = token_pipeline \\\n",
    "    .fit(test) \\\n",
    "    .transform(test) \\\n",
    "    .selectExpr(['Party', 'Handle', 'Tweet', 'normal_token.result as Tokens']) \\\n",
    "    .withColumnRenamed('result', 'Tokens')\n",
    "\n",
    "test_vocab = test.select('Tokens') \\\n",
    "    .select(F.explode('Tokens').alias('Terms')) \\\n",
    "    .distinct() \\\n",
    "    .sort('Terms') \\\n",
    "    .toPandas()\n",
    "\n",
    "test_vocab_frequency = test.select('Tokens') \\\n",
    "    .select(F.explode('Tokens').alias('Terms')) \\\n",
    "    .groupBy('Terms').count() \\\n",
    "    .toDF('Terms', 'Count') \\\n",
    "    .sort('Count') \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.toPandas().to_pickle(PATH + r'\\train_tokenized.pickle')\n",
    "train_vocab.to_csv(PATH + r'\\train_vocab.csv')\n",
    "train_vocab_frequency.to_csv(PATH + r'\\train_vocab_frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.toPandas().to_pickle(PATH + r'\\test_tokenized.pickle')\n",
    "test_vocab.to_csv(PATH + r'\\test_vocab.csv')\n",
    "test_vocab_frequency.to_csv(PATH + r'\\test_vocab_frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
